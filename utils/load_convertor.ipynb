{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded\n",
      "   Input: load_dump.csv\n",
      "   Years: All\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE VALUES\n",
    "# ============================================================================\n",
    "\n",
    "INPUT_FILE = \"load_dump.csv\"           # Input CSV/Excel file\n",
    "TARGET_YEARS = None                    # None (all), 2025 (single), or [2024, 2025] (multiple)\n",
    "OUTPUT_FILE = None                     # Auto-generated if None\n",
    "\n",
    "# Zone to column name mapping\n",
    "ZONE_MAPPING = {\n",
    "    1: \"TPCODL Demand\",\n",
    "    2: \"TPWODL Demand\",\n",
    "    3: \"TPNODL Demand\",\n",
    "    4: \"TPSOSDL Demand\",\n",
    "    5: \"Total Demand (as recorded)\"\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"   Input: {INPUT_FILE}\")\n",
    "print(f\"   Years: {TARGET_YEARS if TARGET_YEARS else 'All'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_prepare_data(file_path, target_years=None):\n",
    "    \"\"\"Load CSV/Excel file and filter by years.\"\"\"\n",
    "    print(f\"ðŸ“‚ Loading data from {file_path}...\")\n",
    "    \n",
    "    if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "    \n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    \n",
    "    available_years = sorted(df['time'].dt.year.unique())\n",
    "    print(f\"âœ… Data loaded. Available years: {available_years}\")\n",
    "    \n",
    "    if target_years is not None:\n",
    "        if isinstance(target_years, int):\n",
    "            target_years = [target_years]\n",
    "        \n",
    "        df_filtered = df[df[\"time\"].dt.year.isin(target_years)].copy()\n",
    "        years_str = \", \".join(map(str, target_years))\n",
    "        print(f\"âœ… Filtered for year(s): {years_str}\")\n",
    "    else:\n",
    "        df_filtered = df.copy()\n",
    "        print(f\"âœ… Keeping all years\")\n",
    "    \n",
    "    date_min = df_filtered[\"time\"].min()\n",
    "    date_max = df_filtered[\"time\"].max()\n",
    "    print(f\"   Date range: {date_min} to {date_max}\")\n",
    "    print(f\"   Total records: {len(df_filtered)}\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def pivot_and_rename(df, zone_mapping):\n",
    "    \"\"\"Pivot data by zone and rename columns.\"\"\"\n",
    "    print(\"ðŸ”„ Pivoting table...\")\n",
    "    df_pivot = df.pivot_table(index=\"time\", columns=\"zone_id\", values=\"load\")\n",
    "    \n",
    "    print(\"ðŸ“ Renaming columns...\")\n",
    "    df_pivot.rename(columns=zone_mapping, inplace=True)\n",
    "    df_pivot.index.name = \"Timestamp\"\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    \n",
    "    print(f\"âœ… Pivot complete. Shape: {df_pivot.shape}\")\n",
    "    print(f\"   Columns: {list(df_pivot.columns)}\")\n",
    "    \n",
    "    return df_pivot\n",
    "\n",
    "def fill_zeros(df, numeric_only=True):\n",
    "    \"\"\"Replace zeros with NaN and forward-fill.\"\"\"\n",
    "    print(\"ðŸ”§ Filling zero values...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    if numeric_only:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        df[numeric_cols] = df[numeric_cols].replace(0, np.nan).fillna(method='ffill')\n",
    "    else:\n",
    "        df = df.replace(0, np.nan).fillna(method='ffill')\n",
    "    \n",
    "    print(\"âœ… Zero values replaced and forward-filled\")\n",
    "    return df\n",
    "\n",
    "def round_numeric_columns(df, decimals=2):\n",
    "    \"\"\"Round all numeric columns.\"\"\"\n",
    "    print(f\"ðŸ”¢ Rounding to {decimals} decimals...\")\n",
    "    df = df.copy()\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].round(decimals)\n",
    "    print(f\"âœ… Rounded {len(numeric_cols)} columns\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_data(df, output_path=None, input_file=\"load.xlsx\"):\n",
    "    \"\"\"Save processed data to CSV.\"\"\"\n",
    "    if output_path is None:\n",
    "        stem = Path(input_file).stem\n",
    "        output_path = f\"{stem}_processed.csv\"\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"ðŸ’¾ Data saved to: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"âœ… Helper functions loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROCESSING PIPELINE\n",
      "======================================================================\n",
      "ðŸ“‚ Loading data from load_dump.csv...\n",
      "âœ… Data loaded. Available years: [np.int32(2024), np.int32(2025), np.int32(2026)]\n",
      "âœ… Keeping all years\n",
      "   Date range: 2024-06-04 15:15:00 to 2026-01-15 09:00:00\n",
      "   Total records: 237829\n",
      "ðŸ”„ Pivoting table...\n",
      "ðŸ“ Renaming columns...\n",
      "âœ… Pivot complete. Shape: (47441, 6)\n",
      "   Columns: ['Timestamp', 'TPCODL Demand', 'TPWODL Demand', 'TPNODL Demand', 'TPSOSDL Demand', 'Total Demand (as recorded)']\n",
      "ðŸ’¾ Data saved to: load_dump_processed.csv\n",
      "\n",
      "ðŸ“Š Data Preview:\n",
      "zone_id           Timestamp  TPCODL Demand  TPWODL Demand  TPNODL Demand  \\\n",
      "0       2024-06-04 15:15:00         1822.0         1582.0         1042.0   \n",
      "1       2024-06-04 15:30:00         1845.0         1556.0         1064.0   \n",
      "2       2024-06-04 15:45:00         1830.0         1562.0         1077.0   \n",
      "3       2024-06-04 16:00:00         1865.0         1557.0         1033.0   \n",
      "4       2024-06-04 16:15:00         1860.0         1566.0         1047.0   \n",
      "\n",
      "zone_id  TPSOSDL Demand  Total Demand (as recorded)  \n",
      "0                 540.0                      5439.0  \n",
      "1                 536.0                      5424.0  \n",
      "2                 547.0                      5447.0  \n",
      "3                 575.0                      5516.0  \n",
      "4                 569.0                      5529.0  \n",
      "\n",
      "âœ¨ Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MAIN PIPELINE - Load, Transform, Save\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROCESSING PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Load and prepare\n",
    "df = load_and_prepare_data(INPUT_FILE, TARGET_YEARS)\n",
    "\n",
    "# Step 2: Pivot and rename\n",
    "df = pivot_and_rename(df, ZONE_MAPPING)\n",
    "\n",
    "# Step 3: OPTIONAL - Uncomment to fill zeros\n",
    "# df = fill_zeros(df)\n",
    "\n",
    "# Step 4: OPTIONAL - Uncomment to round values\n",
    "# df = round_numeric_columns(df, decimals=2)\n",
    "\n",
    "# Step 5: Save\n",
    "output_file = save_data(df, OUTPUT_FILE, INPUT_FILE)\n",
    "\n",
    "# Display preview\n",
    "print(\"\\nðŸ“Š Data Preview:\")\n",
    "print(df.head())\n",
    "print(f\"\\nâœ¨ Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONCATENATING FILES\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‚ Loading parent file: 2025_till_31_march.csv...\n",
      "   Sample timestamps from parent file:\n",
      "   ['01-01-2017 00:00' '01-01-2017 00:15' '01-01-2017 00:30']\n",
      "\n",
      "ðŸ“‚ Loading new file: load_dump_processed_filled.csv...\n",
      "   Sample timestamps from new file:\n",
      "   ['2024-06-04 15:15:00' '2024-06-04 15:30:00' '2024-06-04 15:45:00']\n",
      "\n",
      "â° Parsing PARENT file with format: %d-%m-%Y %H:%M\n",
      "â° Parsing NEW file with format: %Y-%m-%d %H:%M:%S\n",
      "\n",
      "âœ… Timestamps parsed successfully\n",
      "   Parent: 2017-01-01 00:00:00 to 2025-03-31 10:45:00\n",
      "   New: 2024-06-04 15:15:00 to 2026-01-15 09:00:00\n",
      "\n",
      "ðŸ“Š File sizes:\n",
      "   Parent: 289100 rows\n",
      "   New: 56616 rows\n",
      "\n",
      "ðŸ“… Parent file ends at: 2025-03-31 10:45:00\n",
      "   Will append: 27833 new rows\n",
      "\n",
      "âœ… Concatenation complete!\n",
      "   Final size: 316933 rows\n",
      "   Date range: 2017-01-01 00:00:00 to 2026-01-15 09:00:00\n",
      "ðŸ’¾ Saved to: 2026_proper_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FEATURE: Concatenate Files (Parent + New Data)\n",
    "# ============================================================================\n",
    "# Use this cell to merge a parent file (existing data) with new data\n",
    "\n",
    "def concatenate_files(parent_file, new_file, output_path=None, \n",
    "                     parent_date_format=None, new_date_format=None,\n",
    "                     remove_duplicates=True):\n",
    "    \"\"\"\n",
    "    Merge parent file with new data file.\n",
    "    Appends only new rows after parent file's last timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    parent_file : str\n",
    "        Path to parent CSV file\n",
    "    new_file : str\n",
    "        Path to new CSV file\n",
    "    output_path : str\n",
    "        Output file path (optional)\n",
    "    parent_date_format : str\n",
    "        Date format for parent file (e.g., '%d-%m-%Y %H:%M')\n",
    "        If None, will try auto-detection\n",
    "    new_date_format : str\n",
    "        Date format for new file (e.g., '%Y-%m-%d %H:%M:%S')\n",
    "        If None, will try auto-detection\n",
    "    remove_duplicates : bool\n",
    "        Remove duplicate timestamps\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONCATENATING FILES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nðŸ“‚ Loading parent file: {parent_file}...\")\n",
    "    df_parent = pd.read_csv(parent_file)\n",
    "    print(f\"   Sample timestamps from parent file:\")\n",
    "    print(f\"   {df_parent['Timestamp'].head(3).values}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‚ Loading new file: {new_file}...\")\n",
    "    df_new = pd.read_csv(new_file)\n",
    "    print(f\"   Sample timestamps from new file:\")\n",
    "    print(f\"   {df_new['Timestamp'].head(3).values}\")\n",
    "    \n",
    "    # Parse parent file timestamps\n",
    "    if parent_date_format:\n",
    "        print(f\"\\nâ° Parsing PARENT file with format: {parent_date_format}\")\n",
    "        df_parent[\"Timestamp\"] = pd.to_datetime(df_parent[\"Timestamp\"], \n",
    "                                                format=parent_date_format, \n",
    "                                                errors=\"coerce\")\n",
    "    else:\n",
    "        print(f\"\\nâ° Auto-detecting PARENT file format...\")\n",
    "        df_parent[\"Timestamp\"] = pd.to_datetime(df_parent[\"Timestamp\"], \n",
    "                                                errors=\"coerce\")\n",
    "    \n",
    "    # Parse new file timestamps\n",
    "    if new_date_format:\n",
    "        print(f\"â° Parsing NEW file with format: {new_date_format}\")\n",
    "        df_new[\"Timestamp\"] = pd.to_datetime(df_new[\"Timestamp\"], \n",
    "                                            format=new_date_format, \n",
    "                                            errors=\"coerce\")\n",
    "    else:\n",
    "        print(f\"â° Auto-detecting NEW file format...\")\n",
    "        df_new[\"Timestamp\"] = pd.to_datetime(df_new[\"Timestamp\"], \n",
    "                                            errors=\"coerce\")\n",
    "    \n",
    "    # Check for parsing errors\n",
    "    parent_nans = df_parent[\"Timestamp\"].isna().sum()\n",
    "    new_nans = df_new[\"Timestamp\"].isna().sum()\n",
    "    \n",
    "    if parent_nans > 0 or new_nans > 0:\n",
    "        print(f\"\\nâš ï¸  WARNING: Failed to parse some timestamps!\")\n",
    "        if parent_nans > 0:\n",
    "            print(f\"   Parent: {parent_nans} unparseable timestamps\")\n",
    "            print(f\"   Failed samples: {df_parent[df_parent['Timestamp'].isna()]['Timestamp'].head(3).values}\")\n",
    "        if new_nans > 0:\n",
    "            print(f\"   New: {new_nans} unparseable timestamps\")\n",
    "            print(f\"   Failed samples: {df_new[df_new['Timestamp'].isna()]['Timestamp'].head(3).values}\")\n",
    "    \n",
    "    # Show parsed timestamps\n",
    "    print(f\"\\nâœ… Timestamps parsed successfully\")\n",
    "    print(f\"   Parent: {df_parent['Timestamp'].min()} to {df_parent['Timestamp'].max()}\")\n",
    "    print(f\"   New: {df_new['Timestamp'].min()} to {df_new['Timestamp'].max()}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š File sizes:\")\n",
    "    print(f\"   Parent: {len(df_parent)} rows\")\n",
    "    print(f\"   New: {len(df_new)} rows\")\n",
    "    \n",
    "    # Get cutoff timestamp from parent file\n",
    "    parent_last_ts = df_parent[\"Timestamp\"].max()\n",
    "    print(f\"\\nðŸ“… Parent file ends at: {parent_last_ts}\")\n",
    "    \n",
    "    # Filter new data - only keep rows AFTER parent's last timestamp\n",
    "    df_new_filtered = df_new[df_new[\"Timestamp\"] > parent_last_ts].copy()\n",
    "    rows_to_append = len(df_new_filtered)\n",
    "    \n",
    "    if rows_to_append == 0:\n",
    "        print(f\"\\nâš ï¸  WARNING: No new data found after {parent_last_ts}\")\n",
    "        print(f\"   New file date range: {df_new['Timestamp'].min()} to {df_new['Timestamp'].max()}\")\n",
    "        print(f\"   Parent ends in {df_parent['Timestamp'].max().year}, but new file starts in {df_new['Timestamp'].min().year}\")\n",
    "        print(f\"   Make sure the files have overlapping or sequential date ranges!\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"   Will append: {rows_to_append} new rows\")\n",
    "    \n",
    "    # Combine dataframes\n",
    "    df_combined = pd.concat([df_parent, df_new_filtered], ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates if requested\n",
    "    if remove_duplicates:\n",
    "        initial_len = len(df_combined)\n",
    "        df_combined = df_combined.drop_duplicates(subset=[\"Timestamp\"], keep=\"first\")\n",
    "        removed = initial_len - len(df_combined)\n",
    "        if removed > 0:\n",
    "            print(f\"ðŸ—‘ï¸  Removed {removed} duplicate timestamps\")\n",
    "    \n",
    "    print(f\"\\nâœ… Concatenation complete!\")\n",
    "    print(f\"   Final size: {len(df_combined)} rows\")\n",
    "    print(f\"   Date range: {df_combined['Timestamp'].min()} to {df_combined['Timestamp'].max()}\")\n",
    "    \n",
    "    # Save if output path provided\n",
    "    if output_path:\n",
    "        df_combined.to_csv(output_path, index=False)\n",
    "        print(f\"ðŸ’¾ Saved to: {output_path}\")\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "# EXAMPLE USAGE:\n",
    "# Parent file format: DD-MM-YYYY HH:MM (01-01-2017 00:00)\n",
    "# New file format: YYYY-MM-DD HH:MM:SS (2024-06-04 15:15:00)\n",
    "\n",
    "parent_file = \"2025_till_31_march.csv\"\n",
    "new_file = \"load_dump_processed_filled.csv\"\n",
    "df_combined = concatenate_files(\n",
    "    parent_file, \n",
    "    new_file,\n",
    "    output_path=\"2026_proper_data.csv\",\n",
    "    parent_date_format=\"%d-%m-%Y %H:%M\",      # Parent: DD-MM-YYYY HH:MM\n",
    "    new_date_format=\"%Y-%m-%d %H:%M:%S\"       # New: YYYY-MM-DD HH:MM:SS\n",
    ")\n",
    "\n",
    "# COMMON DATE FORMATS:\n",
    "# \"%d-%m-%Y %H:%M\"         -> 01-01-2017 00:00\n",
    "# \"%Y-%m-%d %H:%M:%S\"      -> 2024-06-04 15:15:00\n",
    "# \"%m-%d-%Y %H:%M:%S\"      -> 06-04-2024 15:15:00\n",
    "# \"%d/%m/%Y %H:%M\"         -> 01/01/2017 00:00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ADVANCED: Load & Transform Existing Data\n",
    "# ============================================================================\n",
    "# Use this cell to work with already-processed CSV files\n",
    "\n",
    "# Example 1: Load processed CSV and apply additional transformations\n",
    "# csv_file = \"2025_processed_data.csv\"\n",
    "# df_loaded = pd.read_csv(csv_file)\n",
    "# df_loaded[\"Timestamp\"] = pd.to_datetime(df_loaded[\"Timestamp\"])\n",
    "\n",
    "# # Apply transformations\n",
    "# df_transformed = fill_zeros(df_loaded)\n",
    "# df_transformed = round_numeric_columns(df_transformed, decimals=2)\n",
    "\n",
    "# # Save\n",
    "# save_data(df_transformed, \"2025_processed_cleaned.csv\")\n",
    "\n",
    "# Example 2: Load and check data\n",
    "# df_check = pd.read_csv(\"my_file.csv\")\n",
    "# print(f\"Shape: {df_check.shape}\")\n",
    "# print(f\"Columns: {list(df_check.columns)}\")\n",
    "# print(df_check.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load & Converter\n",
    "\n",
    "Complete pipeline for loading, converting, and processing forecasting data with concatenation support.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. **Cell 2** - Set your configuration (file names, years, etc.)\n",
    "2. **Cell 3** - Load and process data\n",
    "3. **Cell 4** - (Optional) Concatenate with parent file\n",
    "4. **Cell 5** - (Optional) Advanced transformations\n",
    "\n",
    "## Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|------------|\n",
    "| **Load Data** | Parse CSV/Excel with datetime support |\n",
    "| **Filter Years** | Keep all, single, or multiple years |\n",
    "| **Pivot & Rename** | Reorganize zones into readable columns |\n",
    "| **Fill Zeros** | Replace zeros with forward-filled values |\n",
    "| **Round Values** | Round numeric columns to N decimals |\n",
    "| **Concatenate Files** | Merge parent file + new data seamlessly |\n",
    "| **Auto Output** | Generated filenames based on input |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midas-py310-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
